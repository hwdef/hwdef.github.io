<!doctype html><html lang=zh dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=description content="夜晚，能让人呼吸。"><title>使用whisper+ollama+ffmpeg为视频添加中文字幕 | 以梦喂马</title><link rel=icon href=/favicon.ico><style>:root{--accent:#ffcd00}</style><style>:root{--bg:#ffffff;--surface:#f7f7f7;--text:#263238;--muted:#6c7a86;--border:#d6dce2;--link:#1e2a32}@media(prefers-color-scheme:dark){:root{--bg:#0e141b;--surface:#121b24;--text:#e5e7eb;--muted:#9ba3af;--border:#2c3542;--link:#f5f7fa}body{color-scheme:dark}}*,*::before,*::after{box-sizing:border-box}body{margin:0;background:var(--bg);color:var(--text);font-family:-apple-system,BlinkMacSystemFont,segoe ui,Roboto,Oxygen-Sans,Ubuntu,Cantarell,open sans,helvetica neue,sans-serif;line-height:1.75;font-size:18px;color-scheme:light}a{color:var(--link);text-decoration:none;transition:color .15s ease,border-color .15s ease}a:hover,a:focus{color:var(--accent)}.site{min-height:100vh;display:flex;flex-direction:column}.container{width:100%;max-width:740px;padding:0 20px;margin:0 auto}.content-area{flex:1 0 auto;padding:0 0 2.6rem}.site-header{background:var(--bg)}.top-bar{display:flex;align-items:center;gap:1.1rem;justify-content:flex-start;padding-top:1rem;padding-bottom:.2rem;color:var(--muted);font-size:1.05rem}.brand{display:none}.main-nav ul{list-style:none;padding:0;margin:0;display:flex;gap:1.25rem;font-size:1.04rem;letter-spacing:.01em}.main-nav a{padding-bottom:.22rem;border-bottom:2px solid transparent}.main-nav a.active,.main-nav a.ancestor,.main-nav a:hover{border-bottom-color:var(--accent)}.site-hero{padding-top:.6rem;padding-bottom:1.4rem}.hero-title{margin:0 0 .4rem;font-size:2.6rem;font-weight:700;letter-spacing:.01em}.hero-desc{margin:0 0 .7rem;color:var(--muted);font-style:italic;font-size:1rem}.accent-line{display:inline-block;width:var(--date-col,6.5em);height:4px;background:var(--accent);border-radius:999px;margin:.7rem 0 .35rem;justify-self:start}.section-block{margin-top:2rem}.section-title{margin:0 0 .6rem;font-size:1.5rem;letter-spacing:.015em}.page-header{padding-top:.6rem;padding-bottom:1.4rem}.page-title{margin:0 0 .4rem;font-size:2.6rem;font-weight:700;letter-spacing:.01em}.page-desc{margin:0 0 .7rem;color:var(--muted);font-style:italic;font-size:1rem}.home-wrap{--date-col:6.5em;--col-gap:1rem;display:grid;grid-template-columns:var(--date-col)1fr;grid-column-gap:var(--col-gap);row-gap:.6rem}.home-wrap .hero-title,.home-wrap .hero-desc{grid-column:1/-1}.home-wrap .hero-line{grid-column:1/2;margin-top:.6rem;justify-self:start}.home-wrap .section-title{grid-column:1/-1;margin-top:.8rem}.home-wrap .post-list{grid-column:1/-1}.home-wrap .posts-line{grid-column:1/2;margin-top:.8rem;justify-self:start}.post-list{list-style:none;padding:0;margin:.8rem 0 0;display:grid;grid-template-columns:var(--date-col,6.5em)1fr;grid-column-gap:var(--col-gap,.9rem);grid-row-gap:.75rem}.post-list-item{display:contents}.post-date{color:var(--muted);font-size:1.02rem;min-width:0;display:block}.post-link{font-weight:400;font-size:1.12rem}.entry{margin-top:2rem}.entry-header{padding:2rem 0 1.25rem;border-bottom:2px solid var(--border)}.entry-title{margin:0;font-size:2rem;line-height:1.2}.entry-meta{margin-top:.5rem;color:var(--muted);font-style:italic;display:flex;align-items:center;gap:.5rem;font-size:.95rem}.meta-divider{color:var(--border)}.entry-content{margin-top:2rem}.entry-content p{margin:0 0 1.4rem}.entry-content h2,.entry-content h3,.entry-content h4,.entry-content h5,.entry-content h6{margin-top:2rem;margin-bottom:.75rem}.entry-content blockquote{margin:1.5rem 0;padding-left:1rem;border-left:4px solid var(--border);color:var(--muted);font-style:italic}.entry-content code{background:var(--surface);padding:.15rem .35rem;border-radius:4px;border:1px solid var(--border);font-size:.95em;font-family:Menlo,Consolas,Monaco,Ubuntu Mono,liberation mono,monospace}.entry-content pre{background:var(--surface);border:1px solid var(--border);border-radius:8px;padding:1rem;overflow-x:auto}.entry-content pre code{background:0 0;padding:0;border:0}.entry-content ul,.entry-content ol{padding-left:1.2rem;margin:0 0 1.4rem}.entry-content img{max-width:100%;height:auto;display:block;margin:1.25rem auto}.entry-content table{width:100%;border-collapse:collapse;margin:1.5rem 0;border:1px solid var(--border)}.entry-content th,.entry-content td{border:1px solid var(--border);padding:.5rem .75rem;text-align:left}.entry-tags{display:flex;flex-wrap:wrap;gap:.5rem;margin:2rem 0 0;padding-top:1rem;border-top:1px solid var(--border)}.entry-tags a{border:1px solid var(--border);background:var(--surface);padding:.3rem .75rem;border-radius:999px;font-size:.9rem;color:var(--link)}.entry-nav{display:flex;justify-content:space-between;gap:1rem;margin:2.5rem 0 0;padding-top:1rem;border-top:1px solid var(--border)}.nav-link{font-weight:600}.pagination{display:flex;align-items:center;gap:.4rem;margin:2rem 0;flex-wrap:wrap}.page-link{border:1px solid var(--border);padding:.4rem .7rem;border-radius:.4rem;font-size:.95rem}.page-link.active{background:var(--link);color:var(--bg);border-color:var(--link)}.taxonomy-list{list-style:none;padding:0;margin:2rem 0 0;display:grid;gap:.5rem}.taxonomy-list li{display:flex;justify-content:space-between;border:1px solid var(--border);border-radius:.5rem;padding:.65rem .85rem;background:var(--surface)}.term-count{color:var(--muted)}.site-footer{padding:1.5rem 0 2.3rem;background:var(--bg);margin-top:auto}.social-links{display:flex;gap:.85rem;flex-wrap:wrap;margin:.75rem 0}.social-links a{width:auto;height:auto;display:inline-flex;align-items:center;justify-content:center;color:var(--link)}.social-links svg{width:1.25rem;height:1.25rem;stroke:currentColor;fill:none;stroke-width:2}.copyright{color:var(--muted);font-size:.95rem}@media(max-width:640px){.main-nav ul{flex-wrap:wrap;gap:.6rem 1.1rem}.post-list-item{flex-direction:column;align-items:flex-start}.post-date{min-width:auto}.entry-nav{flex-direction:column}}</style><link rel=stylesheet href=/css/custom.css></head><body class="page section-post"><div class=site><header class=site-header><div class="container top-bar"><nav class=main-nav aria-label="Main navigation"><ul><li><a href=/>主页</a></li><li><a href=/post/>文章</a></li><li><a href=/tags/>标签</a></li><li><a href=/resume/>简历</a></li><li><a href=/about/>关于</a></li></ul></nav></div></header><main id=content class=content-area><article class="entry container"><header class=entry-header><h1 class=entry-title>使用whisper+ollama+ffmpeg为视频添加中文字幕</h1><div class=entry-meta><time datetime=2024-12-16T18:27:11+08:00>2024, Dec 16</time></div></header><div class=entry-content><h2 id=简介>简介</h2><p>在日常学习生活中，许多有价值的资料都是非中文的，例如 Andrej Karpathy 推出的几个与大模型相关的视频，例如经久不衰的 MIT 6.824 分布式系统课程，这些视频系统地讲解了特定领域的知识，时长较长，往往从一小时起步。如果逐句翻译，将耗费大量时间。然而，随着大型模型技术的快速发展，我们可以利用这些技术来翻译和学习这些视频，使我们的学习之路更加顺畅。本文将介绍如何使用 Whisper、Ollama 和 FFmpeg 组建一套完善的非中文视频翻译流程。</p><p>whipser 是由 OpenAI 开源的一个基于大规模弱监督实现的语音识别工具，它支持识别超过一百种语言。</p><p><img src=/img/1316513821576085504.png alt></p><p>此外，Whisper 还可以翻译识别到的语言，但它仅支持将结果翻译为英文，无法满足我们对中文的需求。因此，我们需要借助 Ollama 对语音识别的结果进行进一步处理。</p><p>ollama 可以快速部署并运行大模型服务，支持几乎所有的主流大模型，让开发者可以像管理容器和镜像一样管理大模型，通过使用 ollama 部署智脑，Qwen 等大语言模型，我们可以将 Whisper 识别的字幕翻译为中文。</p><p>最后，我们使用 FFmpeg 这一视频处理软件，将字幕与原视频合并，实现流畅的观看体验。</p><h2 id=具体步骤>具体步骤</h2><h3 id=使用-whipser-提取字幕>使用 whipser 提取字幕</h3><p>whisper 的安装和使用都很简单，首先执行下面的命令安装</p><pre><code>pip install -U openai-whisper
</code></pre><p>安装后，运行下面的命令即可从视频中提取 srt 格式的字幕</p><pre><code>whisper video.mp4 --model turbo --language en --output_format srt
</code></pre><p>详细解释下每个参数的作用：</p><p>video.mp4 即需要处理的视频</p><p>&ndash;model 参数指定使用什么模型，whisper 目前支持六种模型，分别是 tiny，base，small，medium，large 和 turbo，模型越大识别效果越好，但相应的识别速度也会更慢，但 turbo 模型不同，turbo 模型是 large 模型的优化版，它提供了与 large 模型相同的识别效果，并且识别速度是 large 模型的 8 倍，比 base 模型还要快，所以这里推荐使用 turbo 模型</p><p>&ndash;language 参数指定了视频的源语言是什么，即使不指定这个参数，whisper 也会智能识别出视频的语言。</p><p>&ndash;output_format 用来设置输出的文件为什么格式，目前支持 txt，vtt，srt，tsv 和 json，每种文件都有其对应的用途，我们只需要字幕，所以此参数只设置 srt 即可，若不设置这个参数，则输出所有格式的文件。</p><h3 id=使用-ollama-将字幕翻译为中文>使用 ollama 将字幕翻译为中文</h3><p>输出结果如下图所示，有字幕索引，时间轴和字幕的具体内容。</p><p><img src=/img/1316834438179704832.png alt></p><p>接下来就需要处理这些英语字幕，我们可以选择各种翻译软件，也可以选择通过本地部署的大模型来翻译，在本文中，我们使用 ollama 部署的大模型来翻译这些字幕，这样做的原因如下：首先本地部署大模型保证了安全性、隐私性，其次通过大模型翻译可以有更高的灵活度，我们可以对翻译后的语气、专业词汇等做进一步调整。</p><p>我们选择 qwen2.5 32B 模型来进行翻译。国产模型对于中文有更好的处理效果。32B 模型是精确度和推理速度上比较适中的选择。</p><p>使用大语言模型翻译字幕时，需要注意以下几个关键点：</p><ol><li><p>在翻译字幕时，如果将字幕文件整个输入到大模型进行推理，字幕索引和时间轴会对推理产生不利影响，并且如果字幕过大，也有可能超出模型的上下文长度限制，所以需要解析字幕文件，将字幕内容识别出，每句单独输入大模型</p></li><li><p>要特别注意与字幕一同输入大模型的 prompt，大模型在微调时，往往会被要求有更“积极”的表现，所以在做翻译任务时，可能会输出除译文外其他的文本，这些文本可能是纠错的，也可能是解释字幕的。</p></li></ol><p>基于上面的要求，优化后的代码如下：</p><pre><code class=language-python>import requests
import re

def parse_srt(content):
    &quot;&quot;&quot;解析SRT文件内容，返回字幕块列表&quot;&quot;&quot;
    pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3} --&gt; \d{2}:\d{2}:\d{2},\d{3})\n((?:.*?\n)*?)(?:\n|$)'
    matches = re.findall(pattern, content, re.MULTILINE)
    return matches

def translate_text(text):
    &quot;&quot;&quot;调用Ollama API翻译单个文本&quot;&quot;&quot;
    prompt = &quot;&quot;&quot;你是一个专业的翻译助手。请将以下英文翻译成中文。
要求：
1. 只输出翻译后的中文文本
2. 不要添加任何解释或额外的文字
3. 翻译要准确、自然、符合中文表达习惯

英文文本：
&quot;&quot;&quot;
    
    data = {
        &quot;model&quot;: &quot;qwen2.5:32b&quot;,
        &quot;prompt&quot;: prompt + text.strip(),
        &quot;stream&quot;: False
    }
    
    try:
        response = requests.post('http://{ollamaapi}/api/generate', 
                               json=data,
                               timeout=60)
        response.raise_for_status()
        result = response.json()
        return result['response'].strip()
    except Exception as e:
        print(f&quot;翻译出错: {str(e)}&quot;)
        return text

def translate_srt(input_file, output_file):
    # 读取SRT文件
    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # 解析字幕文件
    subtitle_blocks = parse_srt(content)
    
    # 准备输出内容
    output_content = &quot;&quot;
    
    # 逐块翻译
    total_blocks = len(subtitle_blocks)
    for i, block in enumerate(subtitle_blocks, 1):
        number = block[0]
        timestamp = block[1]
        text = block[2].strip()
        
        print(f&quot;正在翻译第 {i}/{total_blocks} 条字幕...&quot;)
        translated_text = translate_text(text)
        print(translated_text)
        
        # 组装字幕块
        output_content += f&quot;{number}\n{timestamp}\n{translated_text}\n\n&quot;
    
    # 保存翻译结果
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(output_content)
    
    print(f&quot;翻译完成！结果已保存到 {output_file}&quot;)

if __name__ == &quot;__main__&quot;:
    dir_path = &quot;[1hr Talk] Intro to Large Language Models&quot;
    input_file = f&quot;{dir_path}/en.srt&quot;
    output_file = f&quot;{dir_path}/zh.srt&quot;
    translate_srt(input_file, output_file)
</code></pre><p>翻译后的字幕中文字幕如下；</p><p><img src=/img/1316855047139872768.png alt></p><h3 id=使用-ffmpeg-将字幕与视频合并>使用 ffmpeg 将字幕与视频合并</h3><p>经过了前面的步骤，我们获得了英文和中文的字幕，这些字幕与视频是独立的。在视频播放时，需要手动关联才能看到字幕，增加了操作步骤，这时，我们可以使用 FFmpeg 将两个字幕合并到视频中，将三个文件合成为一个文件，实现流畅的观看体验。FFmpeg 是一个专业处理音视频的软件，几乎所有与视频相关的操作都可以使用它完成。</p><p>执行下面的命令合并视频与字幕</p><pre><code>ffmpeg -i \[1hr\ Talk\]\ Intro\ to\ Large\ Language\ Models.mkv -i zh.srt -i en.srt -c:v copy -c:a copy -c:s srt -map 0 -map 1 -map 2 output.mkv 
</code></pre><p>参数解释：</p><p>-i [1hr\ Talk]\ Intro\ to\ Large\ Language\ Models.mkv 输入视频</p><p>-i zh.srt 输入中文字幕</p><p>-i en.srt 输入英文字幕</p><p>-c:v copy: 复制视频流，不重新编码，可以提升合并速度</p><p>-c:a copy: 复制音频流，不重新编码，可以提升合并速度</p><p>-c:s srt: 使用 srt 格式处理字幕</p><p>-map 0: 包含第一个输入文件(视频)的所有流</p><p>-map 1: 包含第二个输入文件(中文字幕)</p><p>-map 2: 包含第三个输入文件(英文字幕)</p><h3 id=最终效果>最终效果</h3><p>我们可以选择开启英文或中文字幕，也可选择两个字幕同时开启。帮助我们更好理解视频原意。</p><p><img src=/img/1316862047026401280.png alt></p><h2 id=引用>引用</h2><p><a href=https://openai.com/index/whisper/>https://openai.com/index/whisper/</a></p><p><a href=https://github.com/ollama/ollama>https://github.com/ollama/ollama</a></p><p><a href=https://github.com/openai/whisper>https://github.com/openai/whisper</a></p></div><div class=entry-tags><a href=/tags/LLM/>LLM</a>
<a href=/tags/FFmpeg/>FFmpeg</a></div><nav class=entry-nav><a class="nav-link prev" href=/post/lima-docker-private-registry/>← Lima下的docker使用私有镜像仓库</a>
<a class="nav-link next" href=/post/install-official-archlinux-wsl2/>在wsl2中安装官方archlinux →</a></nav></article></main><footer class=site-footer><div class=container><div class=social-links><a href=mailto:hwdefcom@outlook.com aria-label=Email><svg class="icon" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg>
</a><a href=https://github.com/hwdef aria-label=Github><svg class="icon" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a href=https://instagram.com/_limengyang aria-label=Instagram><svg class="icon" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="2" y="2" width="20" height="20" rx="5" ry="5"/><path d="M16 11.37A4 4 0 1112.63 8 4 4 0 0116 11.37z"/><line x1="17.5" y1="6.5" x2="17.51" y2="6.5"/></svg>
</a><a href=https://t.me/hwdef aria-label=Telegram><svg class="icon" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M23.91 3.79 20.3 20.84c-.25 1.21-.98 1.5-2 .94l-5.5-4.07-2.66 2.57c-.3.3-.55.56-1.1.56-.72.0-.6-.27-.84-.95L6.3 13.7.85 12c-1.18-.35-1.19-1.16.26-1.75l21.26-8.2c.97-.43 1.9.24 1.53 1.73z"/></svg></a></div><div class=copyright><p>&copy; 2018–2025 hwdef</p></div></div></footer></div></body></html>