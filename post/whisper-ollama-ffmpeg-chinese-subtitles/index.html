<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='简介 在日常学习生活中，许多有价值的资料都是非中文的，例如 Andrej Karpathy 推出的几个与大模型相关的视频，例如经久不衰的 MIT 6.824 分布式系统课程，这些视频系统地讲'><meta name=theme-color content='#ffcd00'><meta property='og:title' content='使用whisper+ollama+ffmpeg为视频添加中文字幕 • 以梦喂马'><meta property='og:description' content='简介 在日常学习生活中，许多有价值的资料都是非中文的，例如 Andrej Karpathy 推出的几个与大模型相关的视频，例如经久不衰的 MIT 6.824 分布式系统课程，这些视频系统地讲'><meta property='og:url' content='https://hwdef.github.io/post/whisper-ollama-ffmpeg-chinese-subtitles/'><meta property='og:site_name' content='以梦喂马'><meta property='og:type' content='article'><meta property='article:section' content='post'><meta property='article:tag' content='LLM'><meta property='article:tag' content='FFmpeg'><meta property='article:published_time' content='2024-12-16T18:27:11+08:00'><meta property='article:modified_time' content='2024-12-16T18:27:11+08:00'><meta name=twitter:card content='summary'><meta name=generator content="Hugo 0.123.8"><title>使用whisper+ollama+ffmpeg为视频添加中文字幕 • 以梦喂马</title>
<link rel=canonical href=https://hwdef.github.io/post/whisper-ollama-ffmpeg-chinese-subtitles/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/assets/css/main.ab98e12b.css><link rel=stylesheet href=/css/custom.css><style>:root{--color-accent:#ffcd00}</style></head><body class='page type-post'><div class=site><a class=screen-reader-text href=#content>跳到文章</a><div class=main><nav id=main-menu class='menu main-menu' aria-label=主菜单><div class=container><ul><li class=item><a href=https://hwdef.github.io>主页</a></li><li class=item><a href=/post/>文章</a></li><li class=item><a href=/tags/>标签</a></li><li class=item><a href=/resume/>简历</a></li><li class=item><a href=/about/>关于</a></li></ul></div></nav><div class=header-widgets><div class=container></div></div><header id=header class='header site-header'><div class='container sep-after'><div class=header-info><p class='site-title title'>以梦喂马</p><p class='desc site-desc'>夜晚，能让人呼吸。</p></div></div></header><main id=content><article lang=zh class=entry><header class='header entry-header'><div class='container sep-after'><div class=header-info><h1 class=title>使用whisper+ollama+ffmpeg为视频添加中文字幕</h1></div><div class=entry-meta><span class=posted-on><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg>
<span class=screen-reader-text>发布 </span><time class=entry-date datetime=2024-12-16T18:27:11+08:00>2024, Dec 16</time>
</span><span class=reading-time><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 15 15"/></svg>
需要5分钟读完</span></div></div></header><div class='container entry-content'><h2 id=简介>简介</h2><p>在日常学习生活中，许多有价值的资料都是非中文的，例如 Andrej Karpathy 推出的几个与大模型相关的视频，例如经久不衰的 MIT 6.824 分布式系统课程，这些视频系统地讲解了特定领域的知识，时长较长，往往从一小时起步。如果逐句翻译，将耗费大量时间。然而，随着大型模型技术的快速发展，我们可以利用这些技术来翻译和学习这些视频，使我们的学习之路更加顺畅。本文将介绍如何使用 Whisper、Ollama 和 FFmpeg 组建一套完善的非中文视频翻译流程。</p><p>whipser 是由 OpenAI 开源的一个基于大规模弱监督实现的语音识别工具，它支持识别超过一百种语言。</p><p><img src=/img/1316513821576085504.png alt></p><p>此外，Whisper 还可以翻译识别到的语言，但它仅支持将结果翻译为英文，无法满足我们对中文的需求。因此，我们需要借助 Ollama 对语音识别的结果进行进一步处理。</p><p>ollama 可以快速部署并运行大模型服务，支持几乎所有的主流大模型，让开发者可以像管理容器和镜像一样管理大模型，通过使用 ollama 部署智脑，Qwen 等大语言模型，我们可以将 Whisper 识别的字幕翻译为中文。</p><p>最后，我们使用 FFmpeg 这一视频处理软件，将字幕与原视频合并，实现流畅的观看体验。</p><h2 id=具体步骤>具体步骤</h2><h3 id=使用-whipser-提取字幕>使用 whipser 提取字幕</h3><p>whisper 的安装和使用都很简单，首先执行下面的命令安装</p><pre><code>pip install -U openai-whisper
</code></pre><p>安装后，运行下面的命令即可从视频中提取 srt 格式的字幕</p><pre><code>whisper video.mp4 --model turbo --language en --output_format srt
</code></pre><p>详细解释下每个参数的作用：</p><p>video.mp4 即需要处理的视频</p><p>&ndash;model 参数指定使用什么模型，whisper 目前支持六种模型，分别是 tiny，base，small，medium，large 和 turbo，模型越大识别效果越好，但相应的识别速度也会更慢，但 turbo 模型不同，turbo 模型是 large 模型的优化版，它提供了与 large 模型相同的识别效果，并且识别速度是 large 模型的 8 倍，比 base 模型还要快，所以这里推荐使用 turbo 模型</p><p>&ndash;language 参数指定了视频的源语言是什么，即使不指定这个参数，whisper 也会智能识别出视频的语言。</p><p>&ndash;output_format 用来设置输出的文件为什么格式，目前支持 txt，vtt，srt，tsv 和 json，每种文件都有其对应的用途，我们只需要字幕，所以此参数只设置 srt 即可，若不设置这个参数，则输出所有格式的文件。</p><h3 id=使用-ollama-将字幕翻译为中文>使用 ollama 将字幕翻译为中文</h3><p>输出结果如下图所示，有字幕索引，时间轴和字幕的具体内容。</p><p><img src=/img/1316834438179704832.png alt></p><p>接下来就需要处理这些英语字幕，我们可以选择各种翻译软件，也可以选择通过本地部署的大模型来翻译，在本文中，我们使用 ollama 部署的大模型来翻译这些字幕，这样做的原因如下：首先本地部署大模型保证了安全性、隐私性，其次通过大模型翻译可以有更高的灵活度，我们可以对翻译后的语气、专业词汇等做进一步调整。</p><p>我们选择 qwen2.5 32B 模型来进行翻译。国产模型对于中文有更好的处理效果。32B 模型是精确度和推理速度上比较适中的选择。</p><p>使用大语言模型翻译字幕时，需要注意以下几个关键点：</p><ol><li><p>在翻译字幕时，如果将字幕文件整个输入到大模型进行推理，字幕索引和时间轴会对推理产生不利影响，并且如果字幕过大，也有可能超出模型的上下文长度限制，所以需要解析字幕文件，将字幕内容识别出，每句单独输入大模型</p></li><li><p>要特别注意与字幕一同输入大模型的 prompt，大模型在微调时，往往会被要求有更“积极”的表现，所以在做翻译任务时，可能会输出除译文外其他的文本，这些文本可能是纠错的，也可能是解释字幕的。</p></li></ol><p>基于上面的要求，优化后的代码如下：</p><pre><code class=language-python>import requests
import re

def parse_srt(content):
    &quot;&quot;&quot;解析SRT文件内容，返回字幕块列表&quot;&quot;&quot;
    pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3} --&gt; \d{2}:\d{2}:\d{2},\d{3})\n((?:.*?\n)*?)(?:\n|$)'
    matches = re.findall(pattern, content, re.MULTILINE)
    return matches

def translate_text(text):
    &quot;&quot;&quot;调用Ollama API翻译单个文本&quot;&quot;&quot;
    prompt = &quot;&quot;&quot;你是一个专业的翻译助手。请将以下英文翻译成中文。
要求：
1. 只输出翻译后的中文文本
2. 不要添加任何解释或额外的文字
3. 翻译要准确、自然、符合中文表达习惯

英文文本：
&quot;&quot;&quot;
    
    data = {
        &quot;model&quot;: &quot;qwen2.5:32b&quot;,
        &quot;prompt&quot;: prompt + text.strip(),
        &quot;stream&quot;: False
    }
    
    try:
        response = requests.post('http://{ollamaapi}/api/generate', 
                               json=data,
                               timeout=60)
        response.raise_for_status()
        result = response.json()
        return result['response'].strip()
    except Exception as e:
        print(f&quot;翻译出错: {str(e)}&quot;)
        return text

def translate_srt(input_file, output_file):
    # 读取SRT文件
    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # 解析字幕文件
    subtitle_blocks = parse_srt(content)
    
    # 准备输出内容
    output_content = &quot;&quot;
    
    # 逐块翻译
    total_blocks = len(subtitle_blocks)
    for i, block in enumerate(subtitle_blocks, 1):
        number = block[0]
        timestamp = block[1]
        text = block[2].strip()
        
        print(f&quot;正在翻译第 {i}/{total_blocks} 条字幕...&quot;)
        translated_text = translate_text(text)
        print(translated_text)
        
        # 组装字幕块
        output_content += f&quot;{number}\n{timestamp}\n{translated_text}\n\n&quot;
    
    # 保存翻译结果
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(output_content)
    
    print(f&quot;翻译完成！结果已保存到 {output_file}&quot;)

if __name__ == &quot;__main__&quot;:
    dir_path = &quot;[1hr Talk] Intro to Large Language Models&quot;
    input_file = f&quot;{dir_path}/en.srt&quot;
    output_file = f&quot;{dir_path}/zh.srt&quot;
    translate_srt(input_file, output_file)
</code></pre><p>翻译后的字幕中文字幕如下；</p><p><img src=/img/1316855047139872768.png alt></p><h3 id=使用-ffmpeg-将字幕与视频合并>使用 ffmpeg 将字幕与视频合并</h3><p>经过了前面的步骤，我们获得了英文和中文的字幕，这些字幕与视频是独立的。在视频播放时，需要手动关联才能看到字幕，增加了操作步骤，这时，我们可以使用 FFmpeg 将两个字幕合并到视频中，将三个文件合成为一个文件，实现流畅的观看体验。FFmpeg 是一个专业处理音视频的软件，几乎所有与视频相关的操作都可以使用它完成。</p><p>执行下面的命令合并视频与字幕</p><pre><code>ffmpeg -i \[1hr\ Talk\]\ Intro\ to\ Large\ Language\ Models.mkv -i zh.srt -i en.srt -c:v copy -c:a copy -c:s srt -map 0 -map 1 -map 2 output.mkv 
</code></pre><p>参数解释：</p><p>-i [1hr\ Talk]\ Intro\ to\ Large\ Language\ Models.mkv 输入视频</p><p>-i zh.srt 输入中文字幕</p><p>-i en.srt 输入英文字幕</p><p>-c:v copy: 复制视频流，不重新编码，可以提升合并速度</p><p>-c:a copy: 复制音频流，不重新编码，可以提升合并速度</p><p>-c:s srt: 使用 srt 格式处理字幕</p><p>-map 0: 包含第一个输入文件(视频)的所有流</p><p>-map 1: 包含第二个输入文件(中文字幕)</p><p>-map 2: 包含第三个输入文件(英文字幕)</p><h3 id=最终效果>最终效果</h3><p>我们可以选择开启英文或中文字幕，也可选择两个字幕同时开启。帮助我们更好理解视频原意。</p><p><img src=/img/1316862047026401280.png alt></p><h2 id=引用>引用</h2><p><a href=https://openai.com/index/whisper/>https://openai.com/index/whisper/</a></p><p><a href=https://github.com/ollama/ollama>https://github.com/ollama/ollama</a></p><p><a href=https://github.com/openai/whisper>https://github.com/openai/whisper</a></p></div><footer class=entry-footer><div class='container sep-before'><div class=tags><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2H12l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7" y2="7"/></svg>
<span class=screen-reader-text>标签: </span><a class=tag href=/tags/LLM/>LLM</a>, <a class=tag href=/tags/FFmpeg/>FFmpeg</a></div></div></footer></article><nav class=entry-nav><div class=container><div class='prev-entry sep-before'><a href=/post/lima-docker-private-registry/><span aria-hidden=true><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="20" y1="12" x2="4" y2="12"/><polyline points="10 18 4 12 10 6"/></svg>
上一个</span>
<span class=screen-reader-text>上一篇文章: </span>Lima下的docker使用私有镜像仓库</a></div><div class='next-entry sep-before'><a href=/post/install-official-archlinux-wsl2/><span class=screen-reader-text>下一篇文章: </span>在wsl2中安装官方archlinux<span aria-hidden=true>下一个<svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="4" y1="12" x2="20" y2="12"/><polyline points="14 6 20 12 14 18"/></svg></span></a></div></div></nav></main><footer id=footer class=footer><div class='container sep-before'><section class='widget widget-social_menu sep-after'><nav aria-label=社交菜单><ul><li><a href=https://github.com/hwdef target=_blank rel='noopener me'><span class=screen-reader-text>在新标签打开Github的账户</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li><a href=https://instagram.com/_limengyang target=_blank rel='noopener me'><span class=screen-reader-text>在新标签打开Instagram的账户</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="2" y="2" width="20" height="20" rx="5" ry="5"/><path d="M16 11.37A4 4 0 1112.63 8 4 4 0 0116 11.37z"/><line x1="17.5" y1="6.5" x2="17.51" y2="6.5"/></svg></a></li><li><a href=mailto:hwdefcom@outlook.com target=_blank rel='noopener me'><span class=screen-reader-text>通过邮件联系</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg></a></li><li><a href=https://t.me/hwdef target=_blank rel='noopener me'><span class=screen-reader-text>在新标签打开Telegram的账户</span><svg class="icon" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M23.91 3.79 20.3 20.84c-.25 1.21-.98 1.5-2 .94l-5.5-4.07-2.66 2.57c-.3.3-.55.56-1.1.56-.72.0-.6-.27-.84-.95L6.3 13.7.85 12c-1.18-.35-1.19-1.16.26-1.75l21.26-8.2c.97-.43 1.9.24 1.53 1.73z"/></svg></a></li></ul></nav></section><div class=copyright><p>&copy; 2018-2025 hwdef</p></div></div></footer></div></div><script>window.__assets_js_src="/assets/js/"</script><script src=/assets/js/main.c3bcf2df.js></script><script src=/js/custom.js></script></body></html>